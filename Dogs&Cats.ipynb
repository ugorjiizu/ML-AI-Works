{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import Modules","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt   \nimport os\nimport cv2\nimport PIL\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Open Files","metadata":{}},{"cell_type":"code","source":"PETS = r'C:\\Users\\LENOVO\\Desktop\\Izu\\Machine Learning\\Deep Learning\\PetImages'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grabbing Files","metadata":{}},{"cell_type":"code","source":"import pathlib\nPETS = pathlib.Path(PETS)\nimage_count = len(list(PETS.glob('*/*.jpg')))\nimage_count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading File","metadata":{}},{"cell_type":"code","source":"cats = list(PETS.glob('Cat/*.jpg'))\nPIL.Image.open(str(cats[0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Labeling Process","metadata":{}},{"cell_type":"code","source":"Pet_dict = {\n    'Dog': list(PETS.glob('Dog/*.jpg')),\n    'Cat': list(PETS.glob('Cat/*.jpg'))\n}\nPet_labels = {\n    'Dog': 1,\n    'Cat': 0\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(str(Pet_dict['Cat'][0]))\n# cv2.imshow('img', img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seperating Labels and Data","metadata":{}},{"cell_type":"code","source":"X, y = [], []\nfor pet_name, images in Pet_dict.items():\n    for image in images:\n        if 'jpg' in str(image):\n            try:\n                img = cv2.imread(str(image))\n                resized_img = cv2.resize(img,(50,50))\n                X.append(resized_img)\n                y.append(Pet_labels[pet_name])\n            except Exception as e:\n                pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transformng Picture to a Numpy Array","metadata":{}},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\nX.shape, y.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_samp = np.random.choice(X, 4000)\n# X_samp.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting Train and Test data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalizing Data","metadata":{}},{"cell_type":"code","source":"X_train = X_train/255\nX_test = X_test/255","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Augumentation Layer","metadata":{}},{"cell_type":"code","source":"img_height, img_width = 50,50\ndata_aug = Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width,3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN Model","metadata":{}},{"cell_type":"code","source":"num_classes = 2\nmodel = Sequential([\n    data_aug,\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    \n    layers.Flatten(), \n    layers.Dense(128, activation='relu'), \n    layers.Dense(num_classes)\n])\nmodel.compile(optimizer='adam',\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n            metrics=['accuracy'])\n# model.fit(X_train, y_train, epochs=30)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = [], []\nfor pet_name, images in Pet_dict.items():\n    for image in images:\n        if 'jpg' in str(image):\n            try:\n                img = cv2.imread(str(image))\n                resized_img = cv2.resize(img,(224,224))\n                X.append(resized_img)\n                y.append(Pet_labels[pet_name])\n            except Exception as e:\n                pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using Pretrained Model Mobilenet_V2","metadata":{}},{"cell_type":"code","source":"m = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", input_shape=(224,224,3),\n                trainable=False),  # Can be True, see below.\n    tf.keras.layers.Dense(1, activation='softmax')\n])\nm.summary()\nm.compile(optimizer='adam',\n            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n            metrics=['accuracy'])\n# m.fit(X_train, y_train, epochs=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m.evaluate(X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Batching Process","metadata":{}},{"cell_type":"code","source":"pets_ds = tf.keras.preprocessing.image_dataset_from_directory(\nPETS,\nshuffle=True,\nimage_size=(224,224),\nbatch_size=32\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pets_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image Numpy Visualisation","metadata":{}},{"cell_type":"code","source":"for file, label in pets_ds.take(1):\n    print(file.numpy())\n    print(label.numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split Dataset","metadata":{}},{"cell_type":"code","source":"def split_dataset(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 10)\n        \n    ds_size = len(ds)\n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val, test = split_dataset(pets_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train),len(val),len(test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To Multitask CPU and GPU","metadata":{}},{"cell_type":"code","source":"# caching,shuffle and prefetching the data\ntrain = train.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval = val.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest = test.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_classes = 2\n# model = Sequential([\n#     data_aug,\n#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Dropout(0.2),\n    \n#     layers.Flatten(), \n#     layers.Dense(128, activation='relu'), \n#     layers.Dense(num_classes)\n# ])\n# model.compile(optimizer='adam',\n#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#             metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Batch Model","metadata":{}},{"cell_type":"code","source":"m = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", input_shape=(224,224,3),\n                trainable=False),  # Can be True, see below.\n    tf.keras.layers.Dense(1, activation='softmax')\n])\nm.build([32, 224, 224, 3])\nm.summary()\nm.compile(optimizer='adam',\n            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n            metrics=['accuracy'])\n# m.fit(X_train, y_train, epochs=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Model","metadata":{}},{"cell_type":"code","source":"history = m.fit(\n    train, \n    epochs = 5, \n    batch_size = 32, \n    verbose = 1, \n    validation_data = val\n)","metadata":{},"execution_count":null,"outputs":[]}]}