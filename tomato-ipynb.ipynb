{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing Modules required**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pathlib\nimport os\n\n# to disable all debugging logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing Data Set**","metadata":{}},{"cell_type":"code","source":"dir = os.listdir('../input/plant-village/PlantVillage')\n# for filenames in dir:\n#     print(filenames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting Potato Dataset from PlantVillage**","metadata":{}},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_Leaf_Mold ./Tomato_Leaf_Mold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus ./Tomato__Tomato_YellowLeaf__Curl_Virus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_Bacterial_spot ./Tomato_Bacterial_spot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_healthy ./Tomato_healthy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_Spider_mites_Two_spotted_spider_mite ./Tomato_Spider_mites_Two_spotted_spider_mite","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_Early_blight ./Tomato_Early_blight","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato__Target_Spot ./Tomato__Target_Spot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato_Late_blight ./Tomato_Late_blight","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -rf ../input/plant-village/PlantVillage/Tomato__Tomato_mosaic_virus ./Tomato__Tomato_mosaic_virus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Engage the Dataset in Kaggle/Working Dir.**","metadata":{}},{"cell_type":"code","source":"Current_Dir = os.getcwd()\ndataset_dir = pathlib.Path(Current_Dir)\nprint(dataset_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**#Global initialization of variables**","metadata":{}},{"cell_type":"code","source":"Image_Size = 150\nBatch_Size = 50\nChannels = 3\nEPOCHS = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pipeline Initialization**","metadata":{}},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\ndataset_dir,\nshuffle=True,\nimage_size=(Image_Size, Image_Size),\nbatch_size=Batch_Size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Class Names Initialization**","metadata":{}},{"cell_type":"code","source":"class_names=dataset.class_names\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Explore Dataset**","metadata":{}},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring images in a single Batch\nfor images, labels in dataset.take(1):\n    print(images[0].numpy())\n    print(images[0].shape)\n    print(labels.numpy())    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore an Image and its Label\nfor images, labels in dataset.take(1):\n    plt.imshow(images[0].numpy().astype('uint8'))\n    plt.axis('off')\n    plt.title(class_names[labels[0].numpy()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring Multiple Images\nplt.figure(figsize=(12,12))\nfor image_batch, label_batch in dataset.take(1):\n    for i in range(15):\n        plt.subplot(5,3,i+1)\n        plt.imshow(image_batch[i].numpy().astype('uint8'))\n        plt.axis('off')\n        plt.title(class_names[label_batch[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Spliting Dataset for Train , Test and Validation**","metadata":{}},{"cell_type":"code","source":"# Function for Splitting the data\ndef split_dataset(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 10)\n        \n    ds_size = len(ds)\n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val, test = split_dataset(dataset)\nlen(train),len(val),len(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Caching,Shuffling and Prefetching the data for training Optimization**","metadata":{}},{"cell_type":"code","source":"train = train.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval = val.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest = test.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Optimization**","metadata":{}},{"cell_type":"code","source":"# Image Preprocessing Process: Rescaling and Resizing\nresize_and_rescale = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(Image_Size, Image_Size),\n    layers.experimental.preprocessing.Rescaling(1.0/255)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation \ndata_augmentation = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(factor = 0.2)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Building**","metadata":{}},{"cell_type":"code","source":"input_shape=(Image_Size, Image_Size, Channels)\nn_classes=9\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n\n## Loading VGG16 model\nbase_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nbase_model.trainable = False ## Not trainable weights\n\nbase_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****ANN Layer****","metadata":{}},{"cell_type":"code","source":"flatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(50, activation='relu')\ndense_layer_2 = layers.Dense(20, activation='relu')\nprediction_layer = layers.Dense(9, activation='softmax')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Final Model**","metadata":{}},{"cell_type":"code","source":"model = models.Sequential([\n    resize_and_rescale, \n    data_augmentation,\n    base_model,\n    flatten_layer,\n    dense_layer_1,\n    dense_layer_2,\n    prediction_layer\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'],\n)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgghistory = model.fit(\n    train, \n    epochs = EPOCHS, \n    batch_size = Batch_Size, \n    verbose = 1, \n    validation_data = val,\n    callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}